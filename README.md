# ğŸ¤– Tech Challenge - Fase 3 - Fine-Tuning de Foundation Model

Projeto desenvolvido como parte do Tech Challenge da 3Âª fase do curso IADT, cujo objetivo Ã© realizar o fine-tuning de um modelo de fundaÃ§Ã£o (como LLaMA, BERT ou Mistral) utilizando o dataset AmazonTitles-1.3MM.

---

## ğŸ“Œ Objetivo

Treinar um modelo de linguagem capaz de responder perguntas sobre produtos com base nos tÃ­tulos e descriÃ§Ãµes extraÃ­das do dataset `trn.json`, simulando uma interface de perguntas e respostas como um chatbot para e-commerce. .

---

## ğŸ§  Modelo Utilizado

- **Modelo:** Nome_do_Modelo (ex: BERT-base, LLaMA-7B, Mistral-7B, etc)
- **Framework:** Transformers (Hugging Face) / Unsloth / LoRA / PEFT
- **Ambiente de Treinamento:** Google Colab / Local com GPU / etc

---

## ğŸ—‚ï¸ Dataset

- **Nome:** AmazonTitles-1.3MM
- **Fonte:** [Link para o dataset](https://drive.google.com/file/d/12zH4mL2RX8iSvH0VCNnd3QxO4DzuHWnK/view)
- **Arquivo usado:** `trn.json`

### Campos utilizados:

- `title`: tÃ­tulo do produto
- `content`: descriÃ§Ã£o do produto

---

## âš™ï¸ Processo de Fine-Tuning

### ğŸ” PrÃ©-processamento do Dataset

Foi criado o notebook [`preparar_dataset.ipynb`](https://colab.research.google.com/github/techchallangegrupo7/Fase3-Grupo9/blob/main/preparar_dataset.ipynb), responsÃ¡vel por:

- Instalar dependÃªncias automaticamente (`gdown`)
- Baixar o arquivo `trn.json` do Google Drive, caso nÃ£o exista
- Validar e transformar os dados no formato `.jsonl`:
  - Verifica presenÃ§a de tÃ­tulo e descriÃ§Ã£o
  - Gera arquivos com o seguinte formato:
    - **Prompt:** `O que Ã© [title]?`
    - **Completion:** `[content]`
- Exibir relatÃ³rio de registros vÃ¡lidos e ignorados:
  - Quantidade de linhas ignoradas por:
    - Falha de parsing (JSON invÃ¡lido)
    - TÃ­tulo vazio
    - DescriÃ§Ã£o vazia

## ğŸ§ª ConfiguraÃ§Ã£o do Modelo

- Tokenizer e modelo base carregados via Hugging Face
- EstratÃ©gia de fine-tuning:
  - `full fine-tuning` ou `LoRA` com `PEFT`

### ğŸ§¬ Treinamento

- **Batch Size:** X
- **Epochs:** X
- **Learning Rate:** X
- **Ferramentas:** Transformers, Datasets, PEFT

---

## ğŸ’¬ Exemplo de Pergunta e Resposta

```text
Pergunta: O que Ã© Echo Dot (4Âª geraÃ§Ã£o)?
Resposta: Echo Dot Ã© um alto-falante inteligente com Alexa projetado para se adaptar a qualquer ambiente da sua casa...
```

---

## ğŸ“½ï¸ DemonstraÃ§Ã£o

ğŸ¥ Link para o vÃ­deo no YouTube: [Clique aqui](https://www.youtube.com/@Grupo7TechChallenge-IAparaDevs)

---

## ğŸ“ RepositÃ³rio

ğŸ“¦ Link do repositÃ³rio com os cÃ³digos:
ğŸ‘‰ [https://github.com/techchallangegrupo7/Fase3-Grupo9](https://github.com/techchallangegrupo7/Fase3-Grupo9)

---

## ğŸ‘¨â€ğŸ’» Desenvolvedores (Grupo 9)

- **FÃ¡bio Yuiti Takaki** (Discord: `takakisan.`)
- **Luiz Claudio Cunha de Albuquerque** (Discord: `inefavel1305`)
- **Matheus Felipe CondÃ© Rocha** (Discord: `mfconde`)
- **Pedro Vitor Franco de Carvalho** (Discord: `pedro_black10`)
- **Tatiana Yuka Takaki** (Discord: `tatianayk`)

---

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ licenciado sob a licenÃ§a MIT. Consulte o arquivo `LICENSE` para mais informaÃ§Ãµes.
