{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfe71691",
   "metadata": {},
   "source": [
    "# ðŸ“˜ Preparar Dataset para Fine-Tuning (versÃ£o completa com gdown)\n",
    "Este notebook instala `gdown`, baixa o `trn.json` do Google Drive, e gera `dataset_preparado.jsonl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a376fcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Tenta instalar gdown automaticamente caso nÃ£o esteja disponÃ­vel\n",
    "try:\n",
    "    import gdown\n",
    "except ImportError:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"gdown\"])\n",
    "    import gdown\n",
    "\n",
    "# ID do arquivo trn.json compartilhado no Google Drive\n",
    "file_id = \"1kq9bSDUfj0sxGO6C9bb95EYWtey6Smf_\"\n",
    "output = \"trn.json\"\n",
    "\n",
    "# Baixa o arquivo trn.json do Google Drive\n",
    "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output, quiet=False)\n",
    "\n",
    "# Caminho do arquivo de entrada (baixado) e saÃ­da\n",
    "CAMINHO_JSON = \"trn.json\"\n",
    "SAIDA_JSONL = \"dataset_preparado.jsonl\"\n",
    "\n",
    "# FunÃ§Ã£o responsÃ¡vel por preparar os dados no formato necessÃ¡rio para treinamento do modelo\n",
    "def preparar_dataset_jsonl(caminho_entrada, caminho_saida):\n",
    "    contador = 0\n",
    "    ignorados = 0\n",
    "\n",
    "    with open(caminho_entrada, 'r', encoding='utf-8') as f_in, \\\n",
    "         open(caminho_saida, 'w', encoding='utf-8') as f_out:\n",
    "\n",
    "        for linha in f_in:\n",
    "            try:\n",
    "                item = json.loads(linha)\n",
    "                titulo = item.get(\"title\", \"\").strip()\n",
    "                descricao = item.get(\"content\", \"\").strip()\n",
    "\n",
    "                if titulo and descricao:\n",
    "                    prompt = f\"O que Ã© {titulo}?\"\n",
    "                    completion = descricao\n",
    "                    f_out.write(json.dumps({\n",
    "                        \"prompt\": prompt,\n",
    "                        \"completion\": completion\n",
    "                    }, ensure_ascii=False) + '\\n')\n",
    "                    contador += 1\n",
    "                else:\n",
    "                    ignorados += 1\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                ignorados += 1\n",
    "                continue\n",
    "\n",
    "    print(f\"âœ… Dataset gerado com sucesso!\")\n",
    "    print(f\"ðŸ“„ Linhas vÃ¡lidas: {contador}\")\n",
    "    print(f\"ðŸš« Linhas ignoradas (sem conteÃºdo ou erro): {ignorados}\")\n",
    "    print(f\"ðŸ’¾ Arquivo salvo em: {caminho_saida}\")\n",
    "\n",
    "# Executa a funÃ§Ã£o\n",
    "preparar_dataset_jsonl(CAMINHO_JSON, SAIDA_JSONL)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}