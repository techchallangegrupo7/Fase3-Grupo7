{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e66a6c95",
      "metadata": {
        "id": "e66a6c95"
      },
      "source": [
        "# üîΩ Extra√ß√£o e Prepara√ß√£o do Dataset `trn.json` do Google Drive\n",
        "Este notebook realiza as seguintes etapas:\n",
        "1. Monta O Drive, para salvamento\n",
        "2. Instala o pacote `gdown` caso n√£o esteja instalado;\n",
        "3. Baixa um arquivo `.zip` do Google Drive;\n",
        "4. Extrai apenas o arquivo `trn.json` de dentro do `.zip`;\n",
        "5. Remove o `.zip` para economizar espa√ßo em disco;\n",
        "6. Converte o `trn.json` para o formato `.jsonl` com campos `prompt` e `completion`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-vc1NV2JyJzo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vc1NV2JyJzo",
        "outputId": "92c5dbff-2230-4bd5-fd74-4288d60c000d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "## montar o google driver\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17ffddf5",
      "metadata": {
        "id": "17ffddf5"
      },
      "outputs": [],
      "source": [
        "# Instala o gdown automaticamente se necess√°rio\n",
        "import subprocess, sys\n",
        "\n",
        "try:\n",
        "    import gdown\n",
        "except ImportError:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"gdown\"])\n",
        "    import gdown"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "757c1718",
      "metadata": {
        "id": "757c1718"
      },
      "source": [
        "## üìÅ Baixando o ZIP do Google Drive\n",
        "Vamos usar o `gdown` para baixar o arquivo `.zip` diretamente de um link p√∫blico do Google Drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZycQBZICzRgA",
      "metadata": {
        "id": "ZycQBZICzRgA"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"/content/drive/MyDrive/FIAP/tcFase3Grupo9\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf6b348b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "bf6b348b",
        "outputId": "0bc58ef5-0282-429c-e847-7a0fd8117513"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=12zH4mL2RX8iSvH0VCNnd3QxO4DzuHWnK\n",
            "From (redirected): https://drive.google.com/uc?id=12zH4mL2RX8iSvH0VCNnd3QxO4DzuHWnK&confirm=t&uuid=bfdc03da-1465-418a-9f51-7f4fab620e38\n",
            "To: /content/drive/MyDrive/FIAP/tcFase3Grupo9/dados.zip\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 890M/890M [00:20<00:00, 42.5MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/FIAP/tcFase3Grupo9/dados.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "zip_file_id = \"12zH4mL2RX8iSvH0VCNnd3QxO4DzuHWnK\"\n",
        "zip_output = f\"{DATA_DIR}/dados.zip\"\n",
        "\n",
        "# Baixa o arquivo ZIP\n",
        "gdown.download(f\"https://drive.google.com/uc?id={zip_file_id}\", zip_output, quiet=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "814923db",
      "metadata": {
        "id": "814923db"
      },
      "source": [
        "## üì¶ Extraindo apenas o `trn.json` do ZIP\n",
        "Usamos o m√≥dulo `zipfile` da biblioteca padr√£o para extrair somente o arquivo desejado.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2462d78b",
      "metadata": {
        "id": "2462d78b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a2c7be4-f07e-4c02-87e6-03459123877f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Arquivo extra√≠do: /content/drive/MyDrive/FIAP/tcFase3Grupo9/trn.json.gz\n",
            "üìÇ Arquivo GZ descompactado para: /content/drive/MyDrive/FIAP/tcFase3Grupo9/trn.json\n",
            "üóëÔ∏è Pasta tempor√°ria removida: /content/drive/MyDrive/FIAP/tcFase3Grupo9/tmp_extracao\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "import gzip\n",
        "\n",
        "DATA_DIR = \"/content/drive/MyDrive/FIAP/tcFase3Grupo9\"\n",
        "ZIP_NAME = \"dados.zip\"\n",
        "texto_desejado = \"trn.json\"\n",
        "\n",
        "zip_path = os.path.join(DATA_DIR, ZIP_NAME)\n",
        "temp_extract_dir = os.path.join(DATA_DIR, \"tmp_extracao\")\n",
        "os.makedirs(temp_extract_dir, exist_ok=True)\n",
        "\n",
        "extraido = None\n",
        "nome_final = None\n",
        "\n",
        "# Etapa 1: Abrir e localizar arquivo com 'trn.json'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    for arquivo in zip_ref.namelist():\n",
        "        if texto_desejado in os.path.basename(arquivo):\n",
        "            zip_ref.extract(arquivo, temp_extract_dir)\n",
        "            caminho_extraido = os.path.join(temp_extract_dir, arquivo)\n",
        "            nome_extraido = os.path.basename(arquivo)\n",
        "            destino = os.path.join(DATA_DIR, nome_extraido)\n",
        "            shutil.move(caminho_extraido, destino)\n",
        "            extraido = destino\n",
        "            print(f\"‚úÖ Arquivo extra√≠do: {extraido}\")\n",
        "            break\n",
        "\n",
        "# Etapa 2: Descompactar .gz se necess√°rio\n",
        "if extraido:\n",
        "    if extraido.endswith('.gz'):\n",
        "        nome_final = extraido.replace('.gz', '')\n",
        "        with gzip.open(extraido, 'rb') as f_in, open(nome_final, 'wb') as f_out:\n",
        "            shutil.copyfileobj(f_in, f_out)\n",
        "        os.remove(extraido)\n",
        "        print(f\"üìÇ Arquivo GZ descompactado para: {nome_final}\")\n",
        "    elif extraido.endswith('.json'):\n",
        "        nome_final = extraido\n",
        "        print(f\"üìÑ Arquivo JSON pronto para uso: {nome_final}\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Extens√£o desconhecida: {extraido}\")\n",
        "else:\n",
        "    print(\"‚ùå Nenhum arquivo contendo 'trn.json' foi encontrado.\")\n",
        "\n",
        "# Etapa 3: Limpeza da pasta tempor√°ria (sem tocar no conte√∫do do Drive)\n",
        "if os.path.exists(temp_extract_dir):\n",
        "    try:\n",
        "        shutil.rmtree(temp_extract_dir)\n",
        "        print(f\"üóëÔ∏è Pasta tempor√°ria removida: {temp_extract_dir}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Erro ao remover pasta tempor√°ria: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bbb129c",
      "metadata": {
        "id": "1bbb129c"
      },
      "source": [
        "## üìÑ Fun√ß√£o para preparar o JSONL\n",
        "Transformamos o `trn.json` em um arquivo `.jsonl` contendo `prompt` e `completion`, ideal para fine-tuning de modelos de linguagem.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c0de16a",
      "metadata": {
        "id": "2c0de16a"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "import random\n",
        "import html\n",
        "\n",
        "def limpar_html(texto):\n",
        "    # Remove tags HTML\n",
        "    texto = re.sub(r'<[^>]+>', '', texto)\n",
        "    # Converte entidades HTML para caracteres reais\n",
        "    texto = html.unescape(texto)\n",
        "    # Substitui espa√ßos n√£o separ√°veis por espa√ßo normal\n",
        "    texto = texto.replace('\\u00A0', ' ')\n",
        "    # Remove espa√ßos/quebras extras\n",
        "    texto = re.sub(r'\\s+', ' ', texto).strip()\n",
        "    return texto\n",
        "\n",
        "def tem_palavras_coladas(texto):\n",
        "    # Detecta padr√£o letra min√∫scula seguida de mai√∫scula sem espa√ßo\n",
        "    return bool(re.search(r'[a-z][A-Z]', texto))\n",
        "\n",
        "def preparar_dataset_para_unsloth_instruction(caminho_entrada, caminho_saida, limite_linhas=100_000):\n",
        "    frase_indesejada = \"--This text refers to an out of print or unavailable edition of this title.\"\n",
        "\n",
        "    midia_regex = re.compile(\n",
        "        r\"\\b(bbc|cnn|bloomberg|reuters|forbes|washington post|nytimes|the new york times|\"\n",
        "        r\"wall street journal|usa today|los angeles times|san francisco chronicle|\"\n",
        "        r\"the boston globe|newsweek|time magazine|the atlantic|new yorker|slate|\"\n",
        "        r\"the nation|the week)\\b\",\n",
        "        re.IGNORECASE\n",
        "    )\n",
        "\n",
        "    instrucoes = [\n",
        "        \"You are a product seller. Generate a detailed product description based on the title.\",\n",
        "        \"As a salesperson, write a product description for the following title.\",\n",
        "        \"You're writing marketing content for a product. Describe the product with the given title.\",\n",
        "        \"Imagine you're introducing this product to a customer. Create a product summary from this title.\",\n",
        "        \"As a store assistant, explain what this product is based on the title.\",\n",
        "        \"You're preparing a commercial listing. Write a compelling description using the title provided.\"\n",
        "    ]\n",
        "\n",
        "    cont_validas = 0\n",
        "    cont_ignoradas = 0\n",
        "    erros_json = 0\n",
        "    titulos_vazios = 0\n",
        "    descricoes_vazias = 0\n",
        "    ignoradas_por_midia = 0\n",
        "    ignoradas_por_colagem = 0\n",
        "    ignoradas_por_titulo_igual_descricao = 0\n",
        "\n",
        "    with open(caminho_entrada, 'r', encoding='utf-8') as f_in, \\\n",
        "         open(caminho_saida, 'w', encoding='utf-8') as f_out:\n",
        "\n",
        "        for linha in f_in:\n",
        "            if cont_validas >= limite_linhas:\n",
        "                break\n",
        "\n",
        "            try:\n",
        "                data = json.loads(linha)\n",
        "                titulo = data.get(\"title\", \"\").strip()\n",
        "                descricao = data.get(\"content\", \"\").strip()\n",
        "\n",
        "                if not titulo:\n",
        "                    titulos_vazios += 1\n",
        "                    cont_ignoradas += 1\n",
        "                    continue\n",
        "\n",
        "                if not descricao:\n",
        "                    descricoes_vazias += 1\n",
        "                    cont_ignoradas += 1\n",
        "                    continue\n",
        "\n",
        "                if midia_regex.search(descricao):\n",
        "                    ignoradas_por_midia += 1\n",
        "                    cont_ignoradas += 1\n",
        "                    continue\n",
        "\n",
        "                if tem_palavras_coladas(descricao):\n",
        "                    ignoradas_por_colagem += 1\n",
        "                    cont_ignoradas += 1\n",
        "                    continue\n",
        "\n",
        "                # Limpa e remove frase indesejada da descri√ß√£o para comparar\n",
        "                descricao_limpa = limpar_html(descricao.replace(frase_indesejada, \"\")).strip()\n",
        "\n",
        "                # Ignora se t√≠tulo e descri√ß√£o limpos forem iguais (case-insensitive)\n",
        "                if titulo.lower() == descricao_limpa.lower():\n",
        "                    ignoradas_por_titulo_igual_descricao += 1\n",
        "                    cont_ignoradas += 1\n",
        "                    continue\n",
        "\n",
        "                entrada = {\n",
        "                    \"instruction\": random.choice(instrucoes),\n",
        "                    \"input\": titulo,\n",
        "                    \"output\": descricao_limpa\n",
        "                }\n",
        "\n",
        "                f_out.write(json.dumps(entrada, ensure_ascii=False) + '\\n')\n",
        "                cont_validas += 1\n",
        "\n",
        "            except json.JSONDecodeError:\n",
        "                erros_json += 1\n",
        "                cont_ignoradas += 1\n",
        "\n",
        "    print(\"‚úÖ Dataset gerado com sucesso!\")\n",
        "    print(f\"üìÑ Linhas v√°lidas: {cont_validas}\")\n",
        "    print(f\"üö´ Linhas ignoradas: {cont_ignoradas}\")\n",
        "    print(f\"   ‚îî‚îÄ üß® Erros de JSON: {erros_json}\")\n",
        "    print(f\"   ‚îî‚îÄ ‚ùå T√≠tulos vazios: {titulos_vazios}\")\n",
        "    print(f\"   ‚îî‚îÄ ‚ùå Descri√ß√µes vazias: {descricoes_vazias}\")\n",
        "    print(f\"   ‚îî‚îÄ ‚ùå T√≠tulo igual √† descri√ß√£o: {ignoradas_por_titulo_igual_descricao}\")\n",
        "    print(f\"   ‚îî‚îÄ üì∞ Ignoradas por mencionar ve√≠culos de m√≠dia: {ignoradas_por_midia}\")\n",
        "    print(f\"   ‚îî‚îÄ ‚ùå Ignoradas por conter palavras coladas: {ignoradas_por_colagem}\")\n",
        "    print(f\"üíæ Arquivo salvo em: {caminho_saida}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b2797e0",
      "metadata": {
        "id": "3b2797e0"
      },
      "source": [
        "## ‚ñ∂Ô∏è Executando a Prepara√ß√£o dos Dados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1985c630",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1985c630",
        "outputId": "d2e89cd8-b443-465e-cf17-580666101e58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Dataset gerado com sucesso!\n",
            "üìÑ Linhas v√°lidas: 100000\n",
            "üö´ Linhas ignoradas: 172400\n",
            "   ‚îî‚îÄ üß® Erros de JSON: 0\n",
            "   ‚îî‚îÄ ‚ùå T√≠tulos vazios: 20\n",
            "   ‚îî‚îÄ ‚ùå Descri√ß√µes vazias: 84366\n",
            "   ‚îî‚îÄ ‚ùå T√≠tulo igual √† descri√ß√£o: 22\n",
            "   ‚îî‚îÄ üì∞ Ignoradas por mencionar ve√≠culos de m√≠dia: 9287\n",
            "   ‚îî‚îÄ ‚ùå Ignoradas por conter palavras coladas: 78705\n",
            "üíæ Arquivo salvo em: /content/drive/MyDrive/FIAP/tcFase3Grupo9/dataset_preparado_100_alpaca.jsonl\n"
          ]
        }
      ],
      "source": [
        "CAMINHO_JSON = f\"{DATA_DIR}/trn.json\"\n",
        "SAIDA_JSONL = f\"{DATA_DIR}/dataset_preparado_100_alpaca.jsonl\"\n",
        "# preparar_dataset_para_unsloth(CAMINHO_JSON, SAIDA_JSONL)\n",
        "preparar_dataset_para_unsloth_instruction(CAMINHO_JSON, SAIDA_JSONL)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}